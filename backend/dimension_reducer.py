import chromadb
import numpy as np
from sklearn.decomposition import PCA
import pickle
import os
from tqdm import tqdm
from datetime import datetime, timedelta

# ==========================================
# 1. í™˜ê²½ ì„¤ì • (íŒŒì¼ëª… ë° ê²½ë¡œ)
# ==========================================
PERSISTENT_PATH = "data/embedding_db"
SOURCE_COL_NAME = "news_articles_v1"        # ì›ë³¸ ë°ì´í„° ìˆëŠ” ê³³
TARGET_COL_NAME = "reduced_emb"   # 20ì°¨ì› ë°ì´í„° ë„£ì„ ê³³
MODEL_FILENAME = "pca_model_master.pkl"        # pca ëª¨ë¸ íŒŒì¼ ì´ë¦„

# ì‘ì—…í•  ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„ (ì˜ˆì‹œ: ì´ë²ˆ ë‹¬ ë°ì´í„° ì¶”ê°€)
# * ì£¼ì˜: ë§¨ ì²˜ìŒ ì‹¤í–‰í•  ë•ŒëŠ” ë°ì´í„°ê°€ 20ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.
START_DATE = "2024-11-20"
END_DATE = "2025-11-18"


# ==========================================
# 2. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Source)
# ==========================================
client = chromadb.PersistentClient(path=PERSISTENT_PATH)
source_collection = client.get_collection(SOURCE_COL_NAME)

print(f"ğŸ” '{SOURCE_COL_NAME}'ì—ì„œ ë°ì´í„° ê²€ìƒ‰ ì¤‘ ({START_DATE} ~ {END_DATE})...")

def generate_date_range(start_str, end_str):
    start = datetime.strptime(start_str, "%Y-%m-%d")
    end = datetime.strptime(end_str, "%Y-%m-%d")
    date_list = []
    
    curr = start
    while curr <= end:
        date_list.append(curr.strftime("%Y-%m-%d"))
        curr += timedelta(days=1)
    return date_list

# ê¸°ê°„ ë‚´ì˜ ëª¨ë“  ë‚ ì§œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦ (ì˜ˆ: ['2025-08-01', '2025-08-02'])
target_dates = generate_date_range(START_DATE, END_DATE)

print(f"   -> ê²€ìƒ‰ ëŒ€ìƒ ë‚ ì§œ: {target_dates}")

# í•„í„° ì¡°ê±´: article_dateê°€ target_dates ë¦¬ìŠ¤íŠ¸ ì•ˆì— ìˆëŠ” ê²½ìš°ë§Œ ê°€ì ¸ì˜´
filter_condition = {
    "article_date": {
        "$in": target_dates
    }
}


data = source_collection.get(
    where=filter_condition,
    include=["embeddings", "metadatas"] 
)

ids = data["ids"]
embeddings = data["embeddings"]
metadatas = data["metadatas"]

count = len(ids)
print(f"âœ… ì²˜ë¦¬í•  ë°ì´í„° ê°œìˆ˜: {count}ê°œ")

if count == 0:
    print("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

# ==========================================
# 3. PCA ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒì„± (í•µì‹¬ ë¡œì§)
# ==========================================
reduced_embeddings = []

# [ì¼€ì´ìŠ¤ 1] ëª¨ë¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° -> "ë¶ˆëŸ¬ì™€ì„œ ì“°ê¸°"
if os.path.exists(MODEL_FILENAME):
    print(f"ğŸ“‚ ê¸°ì¡´ ëª¨ë¸ íŒŒì¼({MODEL_FILENAME})ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    print("   ğŸ‘‰ ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ 'ë³€í™˜(Transform)'ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    # 1. ëª¨ë¸ ë¡œë“œ
    with open(MODEL_FILENAME, "rb") as f:
        pca = pickle.load(f)
    
    # 2. ë³€í™˜ (ì ˆëŒ€ fití•˜ì§€ ì•ŠìŒ)
    reduced_embeddings_np = pca.transform(embeddings)
    reduced_embeddings = reduced_embeddings_np.tolist()
    
    # 3. íƒ€ê²Ÿ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ê¸°ì¡´ ê²ƒ ì‚¬ìš©)
    # ë§Œì•½ ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ë§Œë“œëŠ” get_or_create ì‚¬ìš©
    target_collection = client.get_or_create_collection(
        name=TARGET_COL_NAME,
        metadata={"hnsw:space": "cosine"}
    )
    print("   ğŸ‘‰ ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ë°ì´í„°ë¥¼ ì¶”ê°€(Append)í•©ë‹ˆë‹¤.")

# [ì¼€ì´ìŠ¤ 2] ëª¨ë¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° -> "ì²˜ìŒì´ë‹ˆ ìƒˆë¡œ ë§Œë“¤ê¸°"
else:
    print(f"ğŸ†• ëª¨ë¸ íŒŒì¼({MODEL_FILENAME})ì´ ì—†ìŠµë‹ˆë‹¤.")
    print("   ğŸ‘‰ PCA ëª¨ë¸ì„ ìƒˆë¡œ í•™ìŠµ(Fit)í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.")
    
    if count < 20:
        raise ValueError(f"ë°ì´í„°ê°€ {count}ê°œë¿ì´ë¼ 20ì°¨ì› í•™ìŠµì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë” í™•ë³´í•˜ì„¸ìš”.")

    # 1. í•™ìŠµ ë° ë³€í™˜
    pca = PCA(n_components=20)
    reduced_embeddings_np = pca.fit_transform(embeddings)
    reduced_embeddings = reduced_embeddings_np.tolist()
    
    # 2. ëª¨ë¸ ì €ì¥
    with open(MODEL_FILENAME, "wb") as f:
        pickle.dump(pca, f)
    print(f"   ğŸ’¾ ìƒˆ ëª¨ë¸ì´ '{MODEL_FILENAME}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 3. íƒ€ê²Ÿ ì»¬ë ‰ì…˜ ìƒˆë¡œ ë§Œë“¤ê¸° (í˜¹ì‹œ ê¸°ì¡´ì— ì°Œêº¼ê¸°ê°€ ìˆë‹¤ë©´ ì´ˆê¸°í™”)
    try:
        client.delete_collection(TARGET_COL_NAME)
        print(f"   ğŸ—‘ï¸ ê¸°ì¡´ '{TARGET_COL_NAME}' ì»¬ë ‰ì…˜ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
    except:
        pass
        
    target_collection = client.create_collection(
        name=TARGET_COL_NAME,
        metadata={"hnsw:space": "cosine"}
    )
    print("   ğŸ‘‰ ìƒˆ ì»¬ë ‰ì…˜ì„ ìƒì„±í•˜ê³  ë°ì´í„°ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.")

# ==========================================
# 4. ë°ì´í„° ì €ì¥ (Batch Processing)
# ==========================================
BATCH_SIZE = 5000
print(f"\nğŸ“¥ DB ì €ì¥ ì‹œì‘ (ì´ {count}ê±´, ë°°ì¹˜ í¬ê¸° {BATCH_SIZE})...")

for i in tqdm(range(0, count, BATCH_SIZE), desc="Inserting"):
    end_idx = min(i + BATCH_SIZE, count)
    
    target_collection.add(
        ids=ids[i:end_idx],
        embeddings=reduced_embeddings[i:end_idx],
        metadatas=metadatas[i:end_idx]
        
    )

print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ('{TARGET_COL_NAME}' ì»¬ë ‰ì…˜ í™•ì¸)")